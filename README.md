# Performing_Techniques_of_Feature-Engineering

I've performed different techniques of Feature Engineering on Multiple Datasets.

I have used [Jupyter notebook]() for coding.

**Download the datasets from here:- [data1](), [data2](), [data3](), [data4]()!!**

# A Practical Guide to Feature Engineering in Python

Learn the underlying techniques and tools for doing feature engineering and extraction in Python

By: Rising Odegua
Feature engineering is one of the most important skill needed in modern data science and machine learning. It has a major influence in the performance of machine learning models and even the quality of insights derived during Exploratory Data Analysis (EDA). In this article, we are going to learn some important techniques and tools that will help you properly extract, prepare and engineer features from your dataset. 

# What you will learn in this:

* What Feature Engineering is?
* How to handle missing values.
* How to handle categorical features.
* How to handle numerical/continuous features.
* Creating Polynomial features.
* Normalization of features.
* Working with Date/Time features8. Working with Latitudes and Longitudes.

***Follow [notebook](https://github.com/Anuragtsl/Performing_Techniques_of_Feature-Engineering/blob/main/Feature%20Engineering.ipynb) for more!!***
 
# What Feature Engineering is?

Feature engineering is the process of using domain knowledge of the data to create features that make machine learning algorithms work (Wikipedia). It is the act of extracting important features from raw data and transforming them into formats that is suitable for machine learning. 

To do Feature Engineering , a data scientist combines domain knowledge (Knowledge about a specific field) with math and programming skills to transform or come up with new features that will help a machine learning model perform better.

Feature Engineering is a practical area of machine learning and is one of the most important aspect of it. Below we highlight what some industry experts have said about it. 

**â€¦some machine learning projects succeed and some fail. What makes the difference? Easily the most important factor is the features used. - Pedro Domingos, "A Few Useful Things to Know about Machine Learning"**

**Coming up with features is difficult, time-consuming, requires expert knowledge. "Applied machine learning" is basically feature engineering. - Andrew Ng, Machine Learning and AI via Brain simulations**

# Conclusion

Feature engineering is important and is the difference between a good machine learning model and the best machine learning model.

In this notebook, we have learnt about some of the techniques and tools for performing feature engineering. We started by defining feature engineering, then looked at some ways to handle missing values Next, we showed some encoding techniques for handling categorical features and various ways for handling numerical features where we specifically talked about log transformations, polynomial/cross features and use of domain expertise in creating new features. Next, we talked about some normalization strategy available in sklearn, how to work with DateTime features and finally, how to handle Geo features like latitudes and longitudes. 

# Preview

![Image1](https://github.com/Anuragtsl/Performing_Techniques_of_Feature-Engineering/blob/main/Images/1.png)

![Image2](https://github.com/Anuragtsl/Performing_Techniques_of_Feature-Engineering/blob/main/Images/2.png)

![Image3](https://github.com/Anuragtsl/Performing_Techniques_of_Feature-Engineering/blob/main/Images/3.png)


#Njoy!
